{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ppo import PPO\n",
    "from utils import logprobs_from_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilgpt2 were not used when initializing GPT2ForSequenceClassification: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at distilgpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, GPT2Tokenizer\n",
    "from gpt2withvaluehead import GPT2HeadWithValueModel\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "sentiment_model = AutoModelForSequenceClassification.from_pretrained(\"distilgpt2\").to(device)\n",
    "gpt2_model = GPT2HeadWithValueModel.from_pretrained(\"distilgpt2\").to(device)\n",
    "gpt2_model_ref = GPT2HeadWithValueModel.from_pretrained(\"distilgpt2\").to(device)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"distilgpt2\")\n",
    "\n",
    "\n",
    "sentiment_model.config.pad_token_id = tokenizer.eos_token_id\n",
    "gpt2_model.config.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\"\n",
    "\n",
    "\n",
    "#import wandb\n",
    "#wandb.init(project='transformer_ppo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_model(query, batch_size, response_len = 32):    \n",
    "    response_tensors = []\n",
    "    tensor_shape = query['input_ids'].size(0)\n",
    "    for i in range(int(tensor_shape/batch_size)):\n",
    "        with torch.no_grad():\n",
    "            generation_output = gpt2_model.generate(input_ids=query['input_ids'][i*batch_size:(i+1)*batch_size],\n",
    "                                                    attention_mask=query['attention_mask'][i*batch_size:(i+1)*batch_size],\n",
    "                                                    max_length=query['attention_mask'].size(1)+response_len, \n",
    "                                                    do_sample=True, \n",
    "                                                    top_p = 1.0,)\n",
    "        for tensor in generation_output:\n",
    "            response_tensors.append(tensor)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    #return tokenizer.pad(response_tensors)\n",
    "    return tokenizer.pad({'input_ids': response_tensors}, \n",
    "                         padding=True)['input_ids'].to(device)\n",
    "\n",
    "\n",
    "def calculate_scores(combined, batch_size):\n",
    "    scores_tensor = []\n",
    "    for i in range(int(combined.size(0)/batch_size)):\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            scores = torch.squeeze(sentiment_model(input_ids = combined[i*batch_size:(i+1)*batch_size])['logits'], dim=1)\n",
    "        scores_tensor.append(scores)\n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "    return torch.cat(scores_tensor)\n",
    "\n",
    "def get_probs(combined, batch_size, response_len = 32):\n",
    "    \n",
    "    values_tensor, logprobs_tensor, ref_logprobs_tensor = [], [], []\n",
    "    for i in range(int(combined.size(0)/batch_size)):\n",
    "        \n",
    "        response = combined[i*batch_size:(i+1)*batch_size]\n",
    "        with torch.no_grad():\n",
    "            outputs = gpt2_model(input_ids = response)\n",
    "            ref_outputs = gpt2_model_ref(input_ids = response)\n",
    "\n",
    "        # Not ideal to re-run this but afaik you can't get logits from model.generate\n",
    "        logprobs = logprobs_from_logits(outputs['logits'][:,:-1,:], \n",
    "                                        response[:,1:])[:, -response_len:]\n",
    "        \n",
    "        ref_logprobs = logprobs_from_logits(ref_outputs['logits'][:,:-1,:], \n",
    "                                            response[:,1:])[:, -response_len:]\n",
    "\n",
    "        values = torch.squeeze(outputs['values'], dim=2)[:, -response_len-1:-1]\n",
    "        \n",
    "        logprobs_tensor.append(logprobs)\n",
    "        ref_logprobs_tensor.append(ref_logprobs)\n",
    "        values_tensor.append(values)\n",
    "        \n",
    "    return (torch.cat(values_tensor), \n",
    "            torch.cat(logprobs_tensor), \n",
    "            torch.cat(ref_logprobs_tensor))\n",
    "\n",
    "def compute_rewards(scores, logprobs, ref_logprobs):\n",
    "    \"\"\"Compute per token rewards from scores and KL-penalty.\"\"\"\n",
    "    kl = logprobs - ref_logprobs\n",
    "    non_score_reward = -0.1 * kl\n",
    "    rewards = non_score_reward.clone().detach()\n",
    "    rewards[:, -1] += scores\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset json (/home/kip/.cache/huggingface/datasets/json/default-a8082db3ce507167/0.0.0/70d89ed4db1394f028c651589fcab6d6b28dddcabbe39d3b21b4d41f9a708514)\n",
      "Loading cached processed dataset at /home/kip/.cache/huggingface/datasets/json/default-a8082db3ce507167/0.0.0/70d89ed4db1394f028c651589fcab6d6b28dddcabbe39d3b21b4d41f9a708514/cache-8a0405a96bf7a40c.arrow\n",
      "Loading cached processed dataset at /home/kip/.cache/huggingface/datasets/json/default-a8082db3ce507167/0.0.0/70d89ed4db1394f028c651589fcab6d6b28dddcabbe39d3b21b4d41f9a708514/cache-c58f4c71967d723a.arrow\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "datasets = load_dataset(\"json\", field='data', data_files={\n",
    "    \"train\": \"../data/tldr-filtered-test.json\",\n",
    "    \"validation\": \"../data/tldr-filtered-test.json\"\n",
    "})\n",
    "\n",
    "# prep dataset\n",
    "def tokenize_function(examples):\n",
    "    output = tokenizer(examples['content'], max_length=256, truncation=True, padding=True)\n",
    "    return output\n",
    "\n",
    "tokenized_datasets = datasets.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    "    remove_columns = datasets[\"train\"].column_names\n",
    ")\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size=512\n",
    "per_device_batch_size=4\n",
    "\n",
    "def collate_wrapper(batch):\n",
    "    return tokenizer.pad(batch, return_tensors='pt')\n",
    "    \n",
    "loader = DataLoader(tokenized_datasets['train'], batch_size=batch_size, pin_memory=False, collate_fn=collate_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñè         | 1/79 [01:00<1:18:14, 60.18s/it]"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(gpt2_model.parameters(), lr=1e-5)\n",
    "ppo = PPO(model=gpt2_model, \n",
    "          tokenizer=tokenizer, \n",
    "          optimizer=optimizer)\n",
    "          #wandb = wandb)\n",
    "r = []\n",
    "    \n",
    "for batch in tqdm(loader):\n",
    "    batch = batch.to(device)\n",
    "    batch['input_ids'].shape\n",
    "    \n",
    "    response_tensors = []\n",
    "    \n",
    "    response = query_model(batch, \n",
    "                           batch_size=per_device_batch_size)\n",
    "    \n",
    "    #scores = calculate_scores(response, \n",
    "    #                          batch_size=per_device_batch_size)\n",
    "    \n",
    "    values, logprobs, ref_logprobs = get_probs(response, \n",
    "                                               batch_size=per_device_batch_size)\n",
    "    \n",
    "    #rewards = compute_rewards(scores, logprobs, ref_logprobs)\n",
    "    rewards = 1-torch.ne(response, 1169).float()\n",
    "    rewards += 1-torch.ne(response, 1).float()\n",
    "    rewards += 1-torch.ne(response, 0).float()\n",
    "    rewards = rewards[:,-32:]\n",
    "    \n",
    "    ppo.step(logprobs, values, rewards, response, per_device_batch_size)\n",
    "    r.append(rewards.mean())\n",
    "    \n",
    "    #wandb.log({\n",
    "    #    \"reward\": rewards,\n",
    "    #    \"scores\": scores\n",
    "    #})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_outputs = self.model(model_input)\n",
    "logits = model_outputs['logits']\n",
    "vpred = model_outputs['values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 32\n",
    "response[:, -32:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = 1-torch.ne(response, 1169).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_rewards(scores, logprobs, ref_logprobs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logprobs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
